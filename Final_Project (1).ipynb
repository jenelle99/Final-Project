{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CPSC 583 Final Project"
      ],
      "metadata": {
        "id": "tqNx9tTg7Y60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "IMWD3Uhf7Rdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install rdkit"
      ],
      "metadata": {
        "id": "FHeqapUz_GaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "import numpy as np\n",
        "from torch_geometric.datasets import MoleculeNet\n",
        "from torch_geometric.datasets import QM9\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from torch_geometric.loader import DataLoader"
      ],
      "metadata": {
        "id": "TJxjU4RgNFi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load & Preprocess the Data"
      ],
      "metadata": {
        "id": "kZSUE6Zn6CT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Tox21 dataset\n",
        "Tox21 = MoleculeNet('MoleculeNet', \"Tox21\")\n",
        "# Load the QM9 dataset\n",
        "QM9 = QM9(root='data/QM9')\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(dataset):\n",
        "    # Convert the molecular graphs to a graph representation\n",
        "    data_list = [data for data in dataset]\n",
        "\n",
        "    # Split the data into training, validation, and test sets\n",
        "    train_data = data_list[:int(len(data_list)*0.7)]\n",
        "    val_data = data_list[int(len(data_list)*0.7):int(len(data_list)*0.85)]\n",
        "    test_data = data_list[int(len(data_list)*0.85):]\n",
        "\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "# Preprocess the Tox21 dataset\n",
        "Tox21_train, Tox21_val, Tox21_test = preprocess_data(Tox21)\n",
        "\n",
        "# Preprocess the QM9 dataset\n",
        "QM9_train, QM9_val, QM9_test = preprocess_data(QM9)\n",
        "\n",
        "# Create data loaders\n",
        "Tox21_train_loader = DataLoader(Tox21_train, batch_size=64, shuffle=True)\n",
        "Tox21_val_loader = DataLoader(Tox21_val, batch_size=64, shuffle=False)\n",
        "Tox21_test_loader = DataLoader(Tox21_test, batch_size=64, shuffle=False)\n",
        "\n",
        "QM9_train_loader = DataLoader(QM9_train, batch_size=64, shuffle=True)\n",
        "QM9_val_loader = DataLoader(QM9_val, batch_size=64, shuffle=False)\n",
        "QM9_test_loader = DataLoader(QM9_test, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "wqRF0L0z586F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. GNN"
      ],
      "metadata": {
        "id": "jIlw0SAX-Mvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.linear = Linear(hidden_channels, out_channels)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = Linear(in_channels, hidden_channels)\n",
        "        self.fc2 = Linear(hidden_channels, hidden_channels)\n",
        "        self.fc3 = Linear(hidden_channels, 1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GaRi2H_G6BIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Training"
      ],
      "metadata": {
        "id": "osVkIbkX-fK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gnn(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x.float(), data.edge_index, data.batch)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def train_discriminator(model, discriminator, loader, optimizer, criterion):\n",
        "    model.eval()\n",
        "    discriminator.train()\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            out = model(data.x.float(), data.edge_index, data.batch)\n",
        "        fake_data = out.detach()\n",
        "        real_data = torch.randn_like(fake_data)\n",
        "        fake_preds = discriminator(fake_data)\n",
        "        real_preds = discriminator(real_data)\n",
        "        loss = criterion(fake_preds, torch.zeros_like(fake_preds)) + criterion(real_preds, torch.ones_like(real_preds))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "WQpCXTuj-hlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Evaluation"
      ],
      "metadata": {
        "id": "Oq0FBXEU-oHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            out = model(data.x.float(), data.edge_index, data.batch)\n",
        "            y_true_batch = data.y.cpu().numpy()\n",
        "            y_pred_batch = out.cpu().numpy()\n",
        "\n",
        "            nan_mask = np.isnan(y_true_batch)\n",
        "            y_true_batch = np.where(nan_mask, 0, y_true_batch)\n",
        "\n",
        "            y_true.append(y_true_batch)\n",
        "            y_pred.append(y_pred_batch)\n",
        "\n",
        "    y_true = np.concatenate(y_true)\n",
        "    y_pred = np.concatenate(y_pred)\n",
        "\n",
        "    nan_mask = np.isnan(y_pred)\n",
        "    y_pred = np.where(nan_mask, 0, y_pred)\n",
        "\n",
        "    y_pred = (y_pred > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    return accuracy, roc_auc"
      ],
      "metadata": {
        "id": "Hh0buK0h-sSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Training Loop - Tox21"
      ],
      "metadata": {
        "id": "UJzwX2l8-zWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "epochs = 50\n",
        "\n",
        "gnn = GNN(in_channels=Tox21.num_features, hidden_channels=64, out_channels=Tox21.num_classes)\n",
        "optimizer_gnn = torch.optim.Adam(gnn.parameters(), lr=lr)\n",
        "\n",
        "discriminator = Discriminator(in_channels=Tox21.num_classes, hidden_channels=64)\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "criterion_gnn = torch.nn.BCEWithLogitsLoss()\n",
        "criterion_discriminator = torch.nn.BCELoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_gnn(gnn, Tox21_train_loader, optimizer_gnn, criterion_gnn)\n",
        "    train_discriminator(gnn, discriminator, Tox21_train_loader, optimizer_discriminator, criterion_discriminator)\n",
        "\n",
        "    accuracy, roc_auc = evaluate(gnn, Tox21_val_loader, criterion_gnn)\n",
        "    print(f'Epoch: {epoch + 1}, Accuracy: {accuracy}, ROC AUC: {roc_auc}')"
      ],
      "metadata": {
        "id": "janG7Y5cBoLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_runs = 3\n",
        "results = []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    gnn = GNN(in_channels=Tox21.num_features, hidden_channels=64, out_channels=Tox21.num_classes)\n",
        "    optimizer_gnn = torch.optim.Adam(gnn.parameters(), lr=lr)\n",
        "\n",
        "    discriminator = Discriminator(in_channels=Tox21.num_classes, hidden_channels=64)\n",
        "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_gnn(gnn, Tox21_train_loader, optimizer_gnn, criterion_gnn)\n",
        "        train_discriminator(gnn, discriminator, Tox21_train_loader, optimizer_discriminator, criterion_discriminator)\n",
        "\n",
        "    accuracy, roc_auc = evaluate(gnn, Tox21_test_loader, criterion_gnn)\n",
        "    results.append((accuracy, roc_auc))\n",
        "\n",
        "mean_results = np.mean(results, axis=0)\n",
        "std_error_results = np.std(results, axis=0) / np.sqrt(num_runs)\n",
        "\n",
        "print(f'Mean Results: Accuracy={mean_results[0]}, ROC AUC={mean_results[1]}')\n",
        "print(f'Std Error Results: Accuracy={std_error_results[0]}, ROC AUC={std_error_results[1]}')"
      ],
      "metadata": {
        "id": "3eZFp1UrDGFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Training Loop - QM9"
      ],
      "metadata": {
        "id": "OBGPSYFl_7Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "epochs = 50\n",
        "\n",
        "gnn = GNN(in_channels=QM9.num_features, hidden_channels=64, out_channels=QM9.num_classes)\n",
        "optimizer_gnn = torch.optim.Adam(gnn.parameters(), lr=lr)\n",
        "\n",
        "discriminator = Discriminator(in_channels=QM9.num_classes, hidden_channels=64)\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "criterion_gnn = torch.nn.BCEWithLogitsLoss()\n",
        "criterion_discriminator = torch.nn.BCELoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_gnn(gnn, QM9_train_loader, optimizer_gnn, criterion_gnn)\n",
        "    train_discriminator(gnn, discriminator, QM9_train_loader, optimizer_discriminator, criterion_discriminator)\n",
        "\n",
        "    accuracy, roc_auc = evaluate(gnn, QM9_val_loader, criterion_gnn)\n",
        "    print(f'Epoch: {epoch + 1}, Accuracy: {accuracy}, ROC AUC: {roc_auc}')"
      ],
      "metadata": {
        "id": "HAM-e25FAB3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_runs = 3\n",
        "results = []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    gnn = GNN(in_channels=QM9.num_features, hidden_channels=64, out_channels=QM9.num_classes)\n",
        "    optimizer_gnn = torch.optim.Adam(gnn.parameters(), lr=lr)\n",
        "\n",
        "    discriminator = Discriminator(in_channels=QM9.num_classes, hidden_channels=64)\n",
        "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_gnn(gnn, QM9_train_loader, optimizer_gnn, criterion_gnn)\n",
        "        train_discriminator(gnn, discriminator, QM9_train_loader, optimizer_discriminator, criterion_discriminator)\n",
        "\n",
        "    accuracy, roc_auc = evaluate(gnn, QM9_test_loader, criterion_gnn)\n",
        "    results.append((accuracy, roc_auc))\n",
        "\n",
        "mean_results = np.mean(results, axis=0)\n",
        "std_error_results = np.std(results, axis=0) / np.sqrt(num_runs)\n",
        "\n",
        "print(f'Mean Results: Accuracy={mean_results[0]}, ROC AUC={mean_results[1]}')\n",
        "print(f'Std Error Results: Accuracy={std_error_results[0]}, ROC AUC={std_error_results[1]}')"
      ],
      "metadata": {
        "id": "boYwKF_DMQ1R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}